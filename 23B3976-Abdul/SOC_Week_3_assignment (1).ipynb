{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJ7uyRFcUzuX"
   },
   "source": [
    "**<h1>Your very fist project</h1>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_p32LI4lVJKP"
   },
   "source": [
    "**You can use Google but please don't use ChatGPT or Gemini or any other generative AI. You are here to learn.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXXjT8ukVUfn"
   },
   "source": [
    "**Dataset Link:** https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset?select=breast-cancer.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Wi-cF89WBpN"
   },
   "source": [
    "**M - Malignant (cancerous)<br>\n",
    "B - Benign (non-cancerous)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAiCg4dBWm7f"
   },
   "source": [
    "**Instructions:<br>\n",
    "Step 1:Load the dataset using pandas<br>\n",
    "Step 2:Explore the dataset by printing out few rows, shape of df, info of df, column names etc.<br>\n",
    "Step 3: Check for null values and handle them (if any). Drop the Id column.<br>\n",
    "Step 4: Use your knowledge of feature selection using correlation matrix to select 10 features out of 31. Give proper reasons for the same.<br><br>**\n",
    "*Use this code:<br>*\n",
    "*import seaborn as sns<br>*\n",
    "*df1 = df[ list_of_column_names_required ]<br>*\n",
    "*dataplot = sns.heatmap(df1.corr(), cmap=\"YlGnBu\", annot=True)<br><br>*\n",
    "*Select two features from column_list_1 = ['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'symmetry_mean', 'fractal_dimension_mean']<br><br>*\n",
    "*Select 6 features from column_list_2 = ['diagnosis','concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst', 'fractal_dimension_worst']<br><br>*\n",
    "*Select 2 features from column_list_3 = ['diagnosis','concave points_mean', 'symmetry_mean',\n",
    "       'radius_se', 'perimeter_se', 'area_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se',\n",
    "        'radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst',]<br><br>*\n",
    "**Step 5: Exploratory Data Analysis. Think what you can plot which can convey some useful information. One bar plot, one pie chart and one scatter plot is required. Give proper reasoning of what you have plot.<br>\n",
    "Step 6: Divide df_new (dataframe which only have the selected 10 columns) into X and Y<br>\n",
    "Step 7: Perform train test split with test_size = 0.2<br>\n",
    "Step 8: Normalise<br>\n",
    "Step 9: Train a logistic regression model and print out the classification report (explore from internet) after predicting on X_test<br>\n",
    "Step 10: Train a SVC and print out the classification report<br>\n",
    "Step 11: Train KNN and print out the classification report<br>\n",
    "Step 12: Choose a metric on which you will compare the models. Give proper reason why you chose that metric.<br>\n",
    "Step 13: Using the above metric, state your best model.<br>\n",
    "Step 14: Suppose for example SVC was your best model. Now train a new SVC model but this time consider all the columns of the dataset. Follow the same steps to divide the df into X and Y, performing split,etc.<br>\n",
    "Step 15: Now compare this model with the best model achieved in Step 13.<br>\n",
    "Step 16: Write in 2 lines what you observe. Can you also tell why you observe?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmYqxVQ0nLgV"
   },
   "source": [
    "**After Step 16, assignment ends. <br>\n",
    "Please submit on teams before deadline.<br>\n",
    "HURRAY!! You have made your very first ML project. More to come soon!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "F8wHNLnEc1D8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\abdul\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\abdul\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\abdul\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abdul\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas matplotlib numpy\n",
    "import pandas as pd\n",
    "path='breast-cancer.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of            id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path)\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of            id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0    ...        25.380          17.33           184.60      2019.0   \n",
       "1    ...        24.990          23.41           158.80      1956.0   \n",
       "2    ...        23.570          25.53           152.50      1709.0   \n",
       "3    ...        14.910          26.50            98.87       567.7   \n",
       "4    ...        22.540          16.67           152.20      1575.0   \n",
       "..   ...           ...            ...              ...         ...   \n",
       "564  ...        25.450          26.40           166.10      2027.0   \n",
       "565  ...        23.690          38.25           155.00      1731.0   \n",
       "566  ...        18.980          34.12           126.70      1124.0   \n",
       "567  ...        25.740          39.42           184.60      1821.0   \n",
       "568  ...         9.456          30.37            59.16       268.6   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 32 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "diagnosis                  0\n",
       "radius_mean                0\n",
       "texture_mean               0\n",
       "perimeter_mean             0\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             0\n",
       "concave points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             0\n",
       "concavity_se               0\n",
       "concave points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 0\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            0\n",
       "concave points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "null_values = df.isnull().sum()\n",
    "null_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
      "diagnosis                1.000000     0.730029      0.415185        0.742636   \n",
      "radius_mean              0.730029     1.000000      0.323782        0.997855   \n",
      "texture_mean             0.415185     0.323782      1.000000        0.329533   \n",
      "perimeter_mean           0.742636     0.997855      0.329533        1.000000   \n",
      "area_mean                0.708984     0.987357      0.321086        0.986507   \n",
      "smoothness_mean          0.358560     0.170581     -0.023389        0.207278   \n",
      "compactness_mean         0.596534     0.506124      0.236702        0.556936   \n",
      "concavity_mean           0.696360     0.676764      0.302418        0.716136   \n",
      "symmetry_mean            0.330499     0.147741      0.071401        0.183027   \n",
      "fractal_dimension_mean  -0.012838    -0.311631     -0.076437       -0.261477   \n",
      "\n",
      "                        area_mean  smoothness_mean  compactness_mean  \\\n",
      "diagnosis                0.708984         0.358560          0.596534   \n",
      "radius_mean              0.987357         0.170581          0.506124   \n",
      "texture_mean             0.321086        -0.023389          0.236702   \n",
      "perimeter_mean           0.986507         0.207278          0.556936   \n",
      "area_mean                1.000000         0.177028          0.498502   \n",
      "smoothness_mean          0.177028         1.000000          0.659123   \n",
      "compactness_mean         0.498502         0.659123          1.000000   \n",
      "concavity_mean           0.685983         0.521984          0.883121   \n",
      "symmetry_mean            0.151293         0.557775          0.602641   \n",
      "fractal_dimension_mean  -0.283110         0.584792          0.565369   \n",
      "\n",
      "                        concavity_mean  symmetry_mean  fractal_dimension_mean  \n",
      "diagnosis                     0.696360       0.330499               -0.012838  \n",
      "radius_mean                   0.676764       0.147741               -0.311631  \n",
      "texture_mean                  0.302418       0.071401               -0.076437  \n",
      "perimeter_mean                0.716136       0.183027               -0.261477  \n",
      "area_mean                     0.685983       0.151293               -0.283110  \n",
      "smoothness_mean               0.521984       0.557775                0.584792  \n",
      "compactness_mean              0.883121       0.602641                0.565369  \n",
      "concavity_mean                1.000000       0.500667                0.336783  \n",
      "symmetry_mean                 0.500667       1.000000                0.479921  \n",
      "fractal_dimension_mean        0.336783       0.479921                1.000000  \n",
      "                         diagnosis  concave points_se  symmetry_se  \\\n",
      "diagnosis                 1.000000           0.408042    -0.006522   \n",
      "concave points_se         0.408042           1.000000     0.312780   \n",
      "symmetry_se              -0.006522           0.312780     1.000000   \n",
      "fractal_dimension_se      0.077972           0.611044     0.369078   \n",
      "radius_worst              0.776454           0.358127    -0.128121   \n",
      "texture_worst             0.456903           0.086741    -0.077473   \n",
      "perimeter_worst           0.782914           0.394999    -0.103753   \n",
      "area_worst                0.733825           0.342271    -0.110343   \n",
      "smoothness_worst          0.421465           0.215351    -0.012662   \n",
      "compactness_worst         0.590998           0.452888     0.060255   \n",
      "concavity_worst           0.659610           0.549592     0.037119   \n",
      "concave points_worst      0.793566           0.602450    -0.030413   \n",
      "fractal_dimension_worst   0.323872           0.310655     0.078079   \n",
      "\n",
      "                         fractal_dimension_se  radius_worst  texture_worst  \\\n",
      "diagnosis                            0.077972      0.776454       0.456903   \n",
      "concave points_se                    0.611044      0.358127       0.086741   \n",
      "symmetry_se                          0.369078     -0.128121      -0.077473   \n",
      "fractal_dimension_se                 1.000000     -0.037488      -0.003195   \n",
      "radius_worst                        -0.037488      1.000000       0.359921   \n",
      "texture_worst                       -0.003195      0.359921       1.000000   \n",
      "perimeter_worst                     -0.001000      0.993708       0.365098   \n",
      "area_worst                          -0.022736      0.984015       0.345842   \n",
      "smoothness_worst                     0.170568      0.216574       0.225429   \n",
      "compactness_worst                    0.390159      0.475820       0.360832   \n",
      "concavity_worst                      0.379975      0.573975       0.368366   \n",
      "concave points_worst                 0.215204      0.787424       0.359755   \n",
      "fractal_dimension_worst              0.591328      0.093492       0.219122   \n",
      "\n",
      "                         perimeter_worst  area_worst  smoothness_worst  \\\n",
      "diagnosis                       0.782914    0.733825          0.421465   \n",
      "concave points_se               0.394999    0.342271          0.215351   \n",
      "symmetry_se                    -0.103753   -0.110343         -0.012662   \n",
      "fractal_dimension_se           -0.001000   -0.022736          0.170568   \n",
      "radius_worst                    0.993708    0.984015          0.216574   \n",
      "texture_worst                   0.365098    0.345842          0.225429   \n",
      "perimeter_worst                 1.000000    0.977578          0.236775   \n",
      "area_worst                      0.977578    1.000000          0.209145   \n",
      "smoothness_worst                0.236775    0.209145          1.000000   \n",
      "compactness_worst               0.529408    0.438296          0.568187   \n",
      "concavity_worst                 0.618344    0.543331          0.518523   \n",
      "concave points_worst            0.816322    0.747419          0.547691   \n",
      "fractal_dimension_worst         0.138957    0.079647          0.617624   \n",
      "\n",
      "                         compactness_worst  concavity_worst  \\\n",
      "diagnosis                         0.590998         0.659610   \n",
      "concave points_se                 0.452888         0.549592   \n",
      "symmetry_se                       0.060255         0.037119   \n",
      "fractal_dimension_se              0.390159         0.379975   \n",
      "radius_worst                      0.475820         0.573975   \n",
      "texture_worst                     0.360832         0.368366   \n",
      "perimeter_worst                   0.529408         0.618344   \n",
      "area_worst                        0.438296         0.543331   \n",
      "smoothness_worst                  0.568187         0.518523   \n",
      "compactness_worst                 1.000000         0.892261   \n",
      "concavity_worst                   0.892261         1.000000   \n",
      "concave points_worst              0.801080         0.855434   \n",
      "fractal_dimension_worst           0.810455         0.686511   \n",
      "\n",
      "                         concave points_worst  fractal_dimension_worst  \n",
      "diagnosis                            0.793566                 0.323872  \n",
      "concave points_se                    0.602450                 0.310655  \n",
      "symmetry_se                         -0.030413                 0.078079  \n",
      "fractal_dimension_se                 0.215204                 0.591328  \n",
      "radius_worst                         0.787424                 0.093492  \n",
      "texture_worst                        0.359755                 0.219122  \n",
      "perimeter_worst                      0.816322                 0.138957  \n",
      "area_worst                           0.747419                 0.079647  \n",
      "smoothness_worst                     0.547691                 0.617624  \n",
      "compactness_worst                    0.801080                 0.810455  \n",
      "concavity_worst                      0.855434                 0.686511  \n",
      "concave points_worst                 1.000000                 0.511114  \n",
      "fractal_dimension_worst              0.511114                 1.000000  \n",
      "                     diagnosis  concave points_mean  symmetry_mean  radius_se  \\\n",
      "diagnosis             1.000000             0.776614       0.330499   0.567134   \n",
      "concave points_mean   0.776614             1.000000       0.462497   0.698050   \n",
      "symmetry_mean         0.330499             0.462497       1.000000   0.303379   \n",
      "radius_se             0.567134             0.698050       0.303379   1.000000   \n",
      "perimeter_se          0.556141             0.710650       0.313893   0.972794   \n",
      "area_se               0.548236             0.690299       0.223970   0.951830   \n",
      "compactness_se        0.292999             0.490424       0.421659   0.356065   \n",
      "concavity_se          0.253730             0.439167       0.342627   0.332358   \n",
      "concave points_se     0.408042             0.615634       0.393298   0.513346   \n",
      "radius_worst          0.776454             0.830318       0.185728   0.715065   \n",
      "texture_worst         0.456903             0.292752       0.090651   0.194799   \n",
      "perimeter_worst       0.782914             0.855923       0.219169   0.719684   \n",
      "area_worst            0.733825             0.809630       0.177193   0.751548   \n",
      "\n",
      "                     perimeter_se   area_se  compactness_se  concavity_se  \\\n",
      "diagnosis                0.556141  0.548236        0.292999      0.253730   \n",
      "concave points_mean      0.710650  0.690299        0.490424      0.439167   \n",
      "symmetry_mean            0.313893  0.223970        0.421659      0.342627   \n",
      "radius_se                0.972794  0.951830        0.356065      0.332358   \n",
      "perimeter_se             1.000000  0.937655        0.416322      0.362482   \n",
      "area_se                  0.937655  1.000000        0.284840      0.270895   \n",
      "compactness_se           0.416322  0.284840        1.000000      0.801268   \n",
      "concavity_se             0.362482  0.270895        0.801268      1.000000   \n",
      "concave points_se        0.556264  0.415730        0.744083      0.771804   \n",
      "radius_worst             0.697201  0.757373        0.204607      0.186904   \n",
      "texture_worst            0.200371  0.196497        0.143003      0.100241   \n",
      "perimeter_worst          0.721031  0.761213        0.260516      0.226680   \n",
      "area_worst               0.730713  0.811408        0.199371      0.188353   \n",
      "\n",
      "                     concave points_se  radius_worst  texture_worst  \\\n",
      "diagnosis                     0.408042      0.776454       0.456903   \n",
      "concave points_mean           0.615634      0.830318       0.292752   \n",
      "symmetry_mean                 0.393298      0.185728       0.090651   \n",
      "radius_se                     0.513346      0.715065       0.194799   \n",
      "perimeter_se                  0.556264      0.697201       0.200371   \n",
      "area_se                       0.415730      0.757373       0.196497   \n",
      "compactness_se                0.744083      0.204607       0.143003   \n",
      "concavity_se                  0.771804      0.186904       0.100241   \n",
      "concave points_se             1.000000      0.358127       0.086741   \n",
      "radius_worst                  0.358127      1.000000       0.359921   \n",
      "texture_worst                 0.086741      0.359921       1.000000   \n",
      "perimeter_worst               0.394999      0.993708       0.365098   \n",
      "area_worst                    0.342271      0.984015       0.345842   \n",
      "\n",
      "                     perimeter_worst  area_worst  \n",
      "diagnosis                   0.782914    0.733825  \n",
      "concave points_mean         0.855923    0.809630  \n",
      "symmetry_mean               0.219169    0.177193  \n",
      "radius_se                   0.719684    0.751548  \n",
      "perimeter_se                0.721031    0.730713  \n",
      "area_se                     0.761213    0.811408  \n",
      "compactness_se              0.260516    0.199371  \n",
      "concavity_se                0.226680    0.188353  \n",
      "concave points_se           0.394999    0.342271  \n",
      "radius_worst                0.993708    0.984015  \n",
      "texture_worst               0.365098    0.345842  \n",
      "perimeter_worst             1.000000    0.977578  \n",
      "area_worst                  0.977578    1.000000  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'corr_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Plot the heatmap\u001b[39;00m\n\u001b[0;32m     23\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m---> 24\u001b[0m dataplot \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mheatmap(corr_matrix, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYlGnBu\u001b[39m\u001b[38;5;124m\"\u001b[39m, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corr_matrix' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# since diagnosis has elements M and B only convert them to numbers\n",
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
    "column_list_1 = ['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'symmetry_mean', 'fractal_dimension_mean']\n",
    "column_list_2 = ['diagnosis','concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'fractal_dimension_worst']\n",
    "column_list_3 = ['diagnosis','concave points_mean', 'symmetry_mean', 'radius_se', 'perimeter_se', 'area_se', 'compactness_se', 'concavity_se', 'concave points_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst',]\n",
    "df_1= df[column_list_1]\n",
    "df_2= df[column_list_2]\n",
    "df_3= df[column_list_3]\n",
    "corr_1 = df_1.corr()\n",
    "corr_2 = df_2.corr()\n",
    "corr_3 = df_3.corr()\n",
    "print(corr_1)\n",
    "print(corr_2)\n",
    "print(corr_3)\n",
    "\n",
    "\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "dataplot = sns.heatmap(corr_matrix, cmap=\"YlGnBu\", annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_corr = 0.0\n",
    "most_correlated_columns = ()\n",
    "for i in range(len(corr_1.columns)):\n",
    "    for j in range(i + 1, len(corr_1.columns)):\n",
    "        if abs(corr_1.iloc[i, j]) > abs(max_corr):\n",
    "            max_corr = corr_1.iloc[i, j]\n",
    "            most_correlated_columns = (corr_1.columns[i], corr_1.columns[j])\n",
    "print(\"The two most correlated columns are:\", most_correlated_columns)\n",
    "print(\"Correlation value:\", max_corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since both columnlist2 and 3 have top 3 corrrelated pairs same , I would be looking at 4th pair and if list 3 has 4thpair bigger I would give it 4th pair and list2 other 3 and vice-versa. Since in the next problem we have to divide into features and target and main aim of this datasheet is to find maligant/ benign instead of last pair in list2 which already has a repeated element lets take diagnosis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_corr_pairs = []\n",
    "for i in range(len(corr_2.columns)):\n",
    "    for j in range(i + 1, len(corr_2.columns)):\n",
    "        top_corr_pairs.append((corr_2.iloc[i, j], corr_2.columns[i], corr_2.columns[j]))\n",
    "top_corr_pairs.sort(reverse=True, key=lambda x: x[0])\n",
    "top_features = top_corr_pairs[:5]\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_corr_pairs = []\n",
    "for i in range(len(corr_3.columns)):\n",
    "    for j in range(i + 1, len(corr_3.columns)):\n",
    "        top_corr_pairs.append((corr_3.iloc[i, j], corr_3.columns[i], corr_3.columns[j]))\n",
    "top_corr_pairs.sort(reverse=True, key=lambda x: x[0])\n",
    "top_features = top_corr_pairs[:5]\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 6 features in column_list_2 are radius_worst, perimeter_worst, area_worst, compactness_worst, concavity_worst, diagnosis <br>\n",
    "2 features in column_list_3 are 'radius_se', 'perimeter_se'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This para I wasnt sure so I used gpt\n",
    "A bar plot can compare the mean values of different features (e.g., mean radius, mean texture) between different diagnosis categories (Malignant vs. Benign). This helps in understanding if there are significant differences in mean feature values between the two classes.<br>\n",
    "A pie chart can show the distribution of diagnoses (Malignant vs. Benign) in the dataset. This provides a quick overview of the proportion of each diagnosis category, which is essential for understanding the dataset's composition<br>\n",
    "A scatter plot can visualize the relationship between two different features (e.g., radius_mean vs. texture_mean). This helps in identifying any patterns or correlations between variables, which can inform further analysis or modeling decisions.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (569, 9)\n",
      "Shape of Y: (569,)\n"
     ]
    }
   ],
   "source": [
    "col_new = ['radius_mean', 'perimeter_mean', 'radius_worst', 'perimeter_worst','compactness_worst', 'concavity_worst', 'area_worst', 'radius_se', 'perimeter_se','diagnosis']\n",
    "df_new = df[col_new].copy()\n",
    "\n",
    "\n",
    "\n",
    "X = df_new[['radius_mean', 'perimeter_mean', 'radius_worst', 'perimeter_worst','compactness_worst', 'concavity_worst', 'area_worst', 'radius_se', 'perimeter_se']]  # Features\n",
    "Y = df_new['diagnosis']\n",
    "\n",
    "# Print the shapes to verify\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of Y:\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (455, 9)\n",
      "Shape of X_test: (114, 9)\n",
      "Shape of Y_train: (455,)\n",
      "Shape of Y_test: (114,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=16)\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of Y_train:\", Y_train.shape)\n",
    "print(\"Shape of Y_test:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_scaled: (455, 9)\n",
      "Shape of X_test_scaled: (114, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"Shape of X_train_scaled:\", X_train_scaled.shape)\n",
    "print(\"Shape of X_test_scaled:\", X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        73\n",
      "           1       1.00      0.80      0.89        41\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.95      0.90      0.92       114\n",
      "weighted avg       0.94      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, Y_train)\n",
    "Y_pred = model.predict(X_test_scaled)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        73\n",
      "           1       0.97      0.93      0.95        41\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train_scaled, Y_train)\n",
    "Y_pred = svc_model.predict(X_test_scaled)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        73\n",
      "           1       0.95      0.88      0.91        41\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_scaled, Y_train)\n",
    "Y_pred = knn_model.predict(X_test_scaled)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Recall = 0.80, F1-Score = 0.89\n",
      "SVC: Recall = 0.93, F1-Score = 0.95\n",
      "KNN: Recall = 0.88, F1-Score = 0.91\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_train_scaled, Y_train, X_test_scaled, Y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, Y_train)\n",
    "    # Make predictions\n",
    "    Y_pred = model.predict(X_test_scaled)\n",
    "    # Print classification report\n",
    "    report = classification_report(Y_test, Y_pred, output_dict=True)\n",
    "    # Extract Recall and F1-Score for the positive class ('1' for malignant)\n",
    "    recall = report['1']['recall']\n",
    "    f1_score = report['1']['f1-score']\n",
    "    return recall, f1_score\n",
    "lr_model = LogisticRegression()\n",
    "lr_recall, lr_f1 = evaluate_model(lr_model, X_train_scaled, Y_train, X_test_scaled, Y_test)\n",
    "svc_model = SVC()\n",
    "svc_recall, svc_f1 = evaluate_model(svc_model, X_train_scaled, Y_train, X_test_scaled, Y_test)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_recall, knn_f1 = evaluate_model(knn_model, X_train_scaled, Y_train, X_test_scaled, Y_test)\n",
    "print(f\"Logistic Regression: Recall = {lr_recall:.2f}, F1-Score = {lr_f1:.2f}\")\n",
    "print(f\"SVC: Recall = {svc_recall:.2f}, F1-Score = {svc_f1:.2f}\")\n",
    "print(f\"KNN: Recall = {knn_recall:.2f}, F1-Score = {knn_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall (Sensitivity) is critical in medical diagnosis to ensure that as many malignant cases as possible are identified.<br>\n",
    "F1-Score provides a balance between precision and recall, which is useful when dealing with imbalanced datasets ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Recall = 0.80, F1-Score = 0.89\n",
      "SVC: Recall = 0.93, F1-Score = 0.95\n",
      "KNN: Recall = 0.88, F1-Score = 0.91\n",
      "\n",
      "Best Model: SVC\n",
      "Recall = 0.93, F1-Score = 0.95\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logistic Regression: Recall = {lr_recall:.2f}, F1-Score = {lr_f1:.2f}\")\n",
    "print(f\"SVC: Recall = {svc_recall:.2f}, F1-Score = {svc_f1:.2f}\")\n",
    "print(f\"KNN: Recall = {knn_recall:.2f}, F1-Score = {knn_f1:.2f}\")\n",
    "models_performance = {\n",
    "    \"Logistic Regression\": {\"recall\": lr_recall, \"f1_score\": lr_f1},\n",
    "    \"SVC\": {\"recall\": svc_recall, \"f1_score\": svc_f1},\n",
    "    \"KNN\": {\"recall\": knn_recall, \"f1_score\": knn_f1}\n",
    "}\n",
    "best_model_name = max(models_performance, key=lambda model: models_performance[model]['recall'])\n",
    "best_model_performance = models_performance[best_model_name]\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Recall = {best_model_performance['recall']:.2f}, F1-Score = {best_model_performance['f1_score']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97        73\n",
      "           1       0.97      0.93      0.95        41\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['diagnosis'])\n",
    "Y = df['diagnosis']\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train_scaled, Y_train)\n",
    "Y_pred = svc_model.predict(X_test_scaled)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both have same output but all features are more preferraable as it gives more input which enables our peogram to predict better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
